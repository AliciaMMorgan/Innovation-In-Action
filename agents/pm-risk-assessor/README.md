# PM Risk Assessor Agent

**Status:** Prompt Library Available (Dec 2025) | Full Agent Implementation (Q1 2026)  
**Purpose:** Identify data governance and execution risks before teams scale analytics, dashboards, or agentic AI systems.

---

## üöÄ Use It Now: Prompt Library

**The PM Risk Assessor is available today as a structured prompt library.**

No API costs. No infrastructure. Works with Claude, ChatGPT, Gemini, or any conversational AI tool you already use.

**[‚Üí Go to Prompt Library](prompts/)**

Five prompts covering:
1. Initial Risk Assessment
2. Data Governance Audit  
3. Pipeline Pattern Analysis
4. Audit Readiness Check
5. Stakeholder Alignment Diagnostic

**[‚Üí See Real Example: STEM Museum Assessment](https://github.com/AliciaMMorgan/Innovation-In-Action/blob/main/agents/pm-risk-assessor/case-vp-stem-data-foundation.md)**

---

## Overview

The PM Risk Assessor translates lessons from scaling mission-critical programs into structured questions and checks. It helps senior PMs and program leaders surface governance gaps, taxonomy failures, and audit readiness issues early‚Äîbefore they become scaling blockers.

This agent bridges the gap between strategic frameworks and practical implementation. It doesn't just automate checklists. It asks the right questions at the right time, informed by patterns from real-world program execution.

---

## Why This Agent Exists

Most organizations rush to implement AI tools or scale analytics without addressing foundational questions:

- Do we have shared taxonomies across partners and systems?
- Who owns this data, and what are our retention obligations?
- How will we demonstrate audit readiness to funders or regulators?
- What happens when feeder patterns (student pipelines, customer journeys, supply chains) cross organizational boundaries?

These aren't theoretical concerns. They're execution gaps that create fragile metrics, compliance risk, and failed scaling attempts. The PM Risk Assessor makes these gaps visible before deployment.

---

## Current Capabilities (Prompt Library - Dec 2025)

### **Risk Prioritization**
Evaluates risks across five categories: taxonomy, data ownership, pipeline patterns, audit readiness, stakeholder alignment. Helps teams focus on issues most likely to block scaling.

### **Data Governance Readiness**  
Assesses taxonomy standardization, ownership clarity, privacy controls, and documentation gaps. Surfaces issues before they become compliance crises.

### **Audit and Validation Checks**
Identifies what evidence you can't produce today that auditors, funders, or certification bodies will request tomorrow.

### **Stakeholder Alignment**
Makes implicit assumptions explicit. Reveals where stakeholders think they agree but actually don't.

### **Pipeline Analysis**
Maps cross-boundary flows and dependencies. Shows where tracking breaks down and bottlenecks emerge.

---

## Planned Capabilities (Full Agent - Q1 2026)

**Interactive Assessment:**
- Agent asks follow-up questions based on your responses
- Adapts to your industry context and regulatory environment
- Generates customized governance roadmaps

**Risk Scoring:**
- Quantified risk levels across all dimensions
- Prioritization based on likelihood, impact, and remediation timeline
- Trend analysis as you implement fixes

**Documentation Generation:**
- Export findings as audit-ready reports
- Generate data sharing agreement templates
- Create governance policy drafts

**Integration:**
- Connect to playbook frameworks from [Cross-Industry PM Playbook](https://github.com/AliciaMMorgan/cross-industry-pm-playbook-ai-transformation)
- Pull real examples from case study library

---

## Foundational Case Study

This agent is informed by real-world experience scaling education programs under strict governance constraints:

**[Read the full case study: Data Governance Foundation for a STEM Pipeline ‚Üí](case-vp-stem-data-foundation.md)**

### Key Lessons Embedded in Agent Design:

1. **Growth without shared taxonomies creates hidden risk**  
   Surveys in silos, inconsistent labels, partner misalignment‚Äîthese patterns recur across industries.

2. **Pipeline patterns must be designed up front**  
   Feeder patterns (K-12 to workforce, customer acquisition to retention) can't be retrofitted after systems ship.

3. **External validations test real maturity**  
   State approvals, outcomes certifications, and audit readiness aren't badges‚Äîthey're practical tests of governance strength.

4. **Quantifiable outcomes prove the framework works**  
   30K‚Üí45K students, $600K+ grants, third-party certifications‚Äîmeasurable results from governed data flows.

---

## Implementation Roadmap

### **‚úÖ Q4 2025: Prompt Library (Complete)**
- Five core assessment prompts available
- Sample assessment from real STEM case study
- Documentation and usage guides
- Works with any conversational AI tool

### **üîÑ Q1 2026: Full Agent Development (In Progress)**
- Interactive agentic workflow using Claude API
- Risk scoring and prioritization algorithms
- Integration with playbook frameworks
- Documentation generation features

### **‚è≥ Q2 2026: Pilot Testing**
- Real-world validation with organizations scaling analytics/AI
- Refinement based on user feedback
- Expansion of case study library with new industry patterns

---

## How This Differs from Task Automation

**Task automation** handles known processes: generating compliance reports, scheduling reviews, routing approvals.

**The PM Risk Assessor** handles ambiguity:
- Evaluating which risks matter most when resources are constrained
- Identifying governance gaps that aren't obvious from checklists
- Asking questions teams don't know to ask until problems emerge
- Adapting prompts based on industry context, regulatory environment, and organizational maturity

It's the difference between executing a workflow and exercising judgment informed by cross-industry patterns.

---

## Get Started

### **Option 1: Use the Prompt Library Today**
**[‚Üí Go to prompts/](prompts/)**

Start with the Initial Risk Assessment or jump to the area where you know you have gaps.

### **Option 2: See It In Action**
**[‚Üí Read the sample assessment](examples/sample-assessment-stem-museum.md)**

Real example showing what each prompt surfaces and how risks were addressed.

### **Option 3: Build on This Work**
All content is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Adapt these prompts to your context, add industry-specific questions, or integrate into your own tools.

---

## Related Resources

- **[Cross-Industry PM Playbook](https://github.com/AliciaMMorgan/cross-industry-pm-playbook-ai-transformation)** - Foundational frameworks this agent operationalizes
- **[Innovation in Action Repository](https://github.com/AliciaMMorgan/Innovation-In-Action)** - Additional case studies and future agents
- **[Case Study: STEM Data Governance](case-vp-stem-data-foundation.md)** - Real execution experience informing agent design

---

## Contributing & Feedback

This is an active development project. If you're a PM, program leader, or technologist working on similar challenges, I'd welcome your input:

- What governance gaps do you encounter most frequently?
- What questions would help surface risks earlier?
- What patterns from your industry should inform the agent's logic?

Open an issue or reach out via [GitHub](https://github.com/AliciaMMorgan).

---

*Part of the Innovation in Action repository demonstrating agentic workflows for traditional organization transformation.*  
*¬© 2025 Alicia M. Morgan | Licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)*
